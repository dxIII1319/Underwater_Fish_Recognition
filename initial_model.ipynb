{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9578048,"sourceType":"datasetVersion","datasetId":5839320}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import necessary libraries\nimport cv2\nimport numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import precision_score, recall_score, accuracy_score\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom scipy.optimize import minimize\nfrom skimage.feature import hog\nimport os\n\n# 1. Load and Preprocess Data with Masks\ndef load_fish4knowledge_data(data_dir, mask_dir):\n    images, masks = [], []\n\n    labels = species_mapping = ['Dascyllus reticulatus', 'Plectroglyphidodon dickii', 'Chromis chrysura', 'Amphiprion clarkia', 'Chaetodon lunulatus', 'Chaetodon trifascialis', 'Myripristis kuntee', 'Acanthurus nigrofuscus','Hemigymnus fasciatus', 'Neoniphon samara', 'Abudefduf vaigiensis', 'Canthigaster valentine', 'Pomacentrus moluccensis', 'Zebrasoma scopas', 'Hemigymnus melapterus', 'Lutjanus fulvus', 'Scolopsis bilineata', 'Scaridae', 'Pempheris vanicolensis','Zanclus cornutus', 'Neoglyphidodon nigroris', 'Balistapus undulatus', 'Siganus fuscescens']\n\n    fish_label = []\n    folder_file_counts = {}\n    folder_species = {}\n\n    for root, dirs, files in os.walk(data_dir):\n        folder_name = os.path.basename(root) or root\n        folder_file_counts[folder_name] = len(files)\n    \n    i = 1\n    for s in species_mapping:\n        folder_species[s] = f'fish_{i:02}'\n        i = i + 1\n    \n    for s in species_mapping:\n        print(f'species: {s}      files: {folder_file_counts[folder_species[s]]}')\n        labels.extend([s] * folder_file_counts[folder_species[s]])\n    \n    # Collect fish images and corresponding masks\n    fish_images = {os.path.splitext(file)[0]: os.path.join(root, file)\n                   for root, _, files in os.walk(data_dir) for file in files if file.endswith('.png')}\n    fish_masks = {os.path.splitext(file)[0]: os.path.join(root, file)\n                  for root, _, files in os.walk(mask_dir) for file in files if file.endswith('.png')}\n    \n    # Pair images with their corresponding masks\n    for key in fish_images:\n        if key in fish_masks:\n            # Load the fish image\n            image = cv2.imread(fish_images[key], cv2.IMREAD_GRAYSCALE)\n            if image is not None:\n                # Resize for consistency\n                image = cv2.resize(image, (200, 200))\n                images.append(image)\n                \n                # Load and process the corresponding mask\n                mask = cv2.imread(fish_masks[key], cv2.IMREAD_GRAYSCALE)\n                if mask is not None:\n                    mask = cv2.resize(mask, (200, 200))\n                    masks.append(mask / 255.0)  # Normalize mask to binary\n            \n            # Use folder name or another identifier for labels if needed\n            labels.append(os.path.basename(os.path.dirname(fish_images[key])))\n\n    return np.array(images), np.array(masks), np.array(labels)\n\n# Define data directories\ndata_dir = '/kaggle/input/fish4knowledge/fish_image'\nmask_dir = '/kaggle/input/fish4knowledge/mask_image'\n\n# Load data with images and masks\nimages, masks, labels = load_fish4knowledge_data(data_dir, mask_dir)\nprint(labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T19:34:44.148711Z","iopub.execute_input":"2024-11-06T19:34:44.149162Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport os\nfrom PIL import ImageDraw, Image\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_probability as tfp\nfrom scipy.ndimage import gaussian_filter, maximum_filter\nimport matplotlib.pyplot as plt\n\n# image = cv2.imread('/kaggle/input/fish23/fish_000007390001_01020.png')\n# blur = cv2.GaussianBlur(image, (5,5), 0)\n# blur_hsv = cv2.cvtColor(blur, cv2.COLOR_BGR2HSV)\n\n# # create NumPy arrays from the boundaries\n# lower = np.array([0,0,0], dtype = \"uint8\")\n# upper = np.array([180,255,40], dtype = \"uint8\")\n\n# # find the colors within the specified boundaries and apply\n# mask = cv2.inRange(blur_hsv, lower, upper)  \n# mask = 255 - mask\n# output = cv2.bitwise_and(image, image, mask = mask)\n# output = Image.fromarray(output)\n# mask = Image.fromarray(mask)\n# # show the images\n# output.save('output.png')\n# mask.save(\"mask.png\")","metadata":{"trusted":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def gaussian_kernel(size: int,\n                    mean: float,\n                    std: float,\n                   ):\n    \"\"\"Makes 2D gaussian Kernel for convolution.\"\"\"\n\n    d = tfp.distributions.Normal(mean, std)\n\n    vals = d.prob(tf.range(start = -size, limit = size + 1, dtype = tf.float32))\n\n    gauss_kernel = tf.einsum('i,j->ij',\n                                  vals,\n                                  vals)\n\n    return gauss_kernel / tf.reduce_sum(gauss_kernel)\n\n\ndef getSaliencyMap(image, mask):\n    \"\"\"\n    Get SaliencyMap using PFT method and apply a mask to only keep maxima within the mask.\n    \n    input ： \n        image shape == H*W*3\n        mask: binary mask of the fish region shape == H*W\n    output ：Saliency Map shape==H*W\n    \"\"\"\n    a_gray = tf.cast(tf.image.rgb_to_grayscale(image), tf.complex64)\n    gauss_kernel = gaussian_kernel(49, 0., 8.)\n    gauss_kernel = gauss_kernel[:, :, tf.newaxis, tf.newaxis]\n\n    a_fft = tf.signal.fft2d(a_gray)\n    phase = tf.math.angle(a_fft)\n    phase = tf.complex(real=tf.math.cos(phase), imag=tf.math.sin(phase))\n    s = tf.signal.ifft2d(phase)\n    salientmap = tf.pow(tf.abs(s), 2)\n    salientmap = tf.expand_dims(salientmap, axis=0)\n\n    salientmap = gaussian_filter(salientmap, sigma=0.1)\n    salientmap = tf.squeeze(salientmap, axis=0)\n    \n    # Apply maximum filter to get suppressed map\n    suppressed_map = maximum_filter(salientmap, size=10)\n    suppressed_map = np.where(salientmap == suppressed_map, salientmap, 0)\n    \n#     maxval = tf.reduce_max(suppressed_map)\n#     minval = tf.reduce_min(suppressed_map)\n#     scale = 255 / (maxval - minval)\n#     suppressed_map = ((suppressed_map - minval) * scale)\n#     mean = tf.reduce_mean(suppressed_map)\n#     suppressed_map = suppressed_map - mean\n#     suppressed_map = (tf.sign(suppressed_map) + 1) / 2\n    \n#     # Ensure the suppressed_map is in numpy format for the mask operation\n#     suppressed_map_np = suppressed_map.numpy()\n    mask_resized = np.array(Image.fromarray(mask).resize((image_rgb.shape[1], image_rgb.shape[0])))\n\n    # Normalize the mask if necessary\n    mask_resized = mask_resized / 255.0\n    # Apply the binary mask to keep only maxima inside the fish region\n    final_map = suppressed_map[:,:, 0] * mask_resized\n    \n    return final_map\n\ndef getTopMaxima(saliency_map, top_n=6):\n    \"\"\"\n    Function to extract the top N maxima from the saliency map.\n    \n    input:\n        saliency_map: numpy array (H * W), the saliency map after applying the mask\n        top_n: Number of top maxima to extract (default is 6)\n        \n    output:\n        top_coords: List of (x, y) coordinates of the top N maxima\n        top_values: List of the top N saliency values\n    \"\"\"\n    # Flatten the saliency map\n    flattened_map = saliency_map.flatten()\n\n    # Get the indices of the top N values\n    top_indices = np.argsort(flattened_map)[-top_n:][::-1]  # Sort in descending order\n    \n    # Convert flat indices back to 2D coordinates\n    top_coords = np.unravel_index(top_indices, saliency_map.shape)\n    \n    # Get the top N values\n    top_values = flattened_map[top_indices]\n    \n    # Return coordinates and values\n    return list(zip(top_coords[0], top_coords[1])), top_values\n\n\ndef drawMaximaOnImage(image, top_coords, radius=5, color='red'):\n    \"\"\"\n    Draw circles around the top maxima on the image.\n    \n    input:\n        image: The original image (PIL Image object)\n        top_coords: List of (x, y) coordinates of the top maxima\n        radius: Radius of the circle to draw\n        color: Color of the circles\n    output:\n        image: The image with the maxima highlighted\n    \"\"\"\n    # Ensure the image is a PIL Image object\n    if isinstance(image, np.ndarray):\n        image = Image.fromarray(image)\n\n    # Create a drawing context\n    draw = ImageDraw.Draw(image)\n\n    # Draw circles at each of the top maxima coordinates\n    for (y, x) in top_coords:\n        # Draw a circle centered at (x, y)\n        draw.ellipse((x - radius, y - radius, x + radius, y + radius), outline=color, width=3)\n    \n    return image\n\ndef load_fish_images_and_masks(base_dir_fish, base_dir_mask):\n    image_paths = []\n    mask_paths = []\n    \n    for root, dirs, files in os.walk(base_dir_fish):\n        for file in files:\n            if file.endswith('.png'):\n                image_paths.append(os.path.join(root, file))\n                \n    for root, dirs, files in os.walk(base_dir_mask):\n        for file in files:\n            if file.endswith('.png'):\n                mask_paths.append(os.path.join(root, file))\n\n    return image_paths, mask_paths\n\n\n# if __name__ == '__main__':\n#     base_dir_fish = '/kaggle/input/fish4knowledge/fish_image'\n#     base_dir_mask = '/kaggle/input/fish4knowledge/mask_image'\n    \n#     image_paths, mask_paths = load_fish_images_and_masks(base_dir_fish, base_dir_mask)\n    \n#     for image_path, mask_path in zip(image_paths, mask_paths):\n#         image = Image.open(image_path)  # Load the image\n#         mask = Image.open(mask_path)    # Load the mask\n\n#         image = np.array(image)\n#         image_rgb = image[:, :, :3]\n\n#         mask = np.array(mask)           # Convert mask to numpy array\n#         mask = mask / 255.0    # Convert mask to binary (assuming mask is grayscale or binary)\n\n#         # Get the saliency map with the mask applied\n#         final_saliency_map = getSaliencyMap(image_rgb, mask)\n\n#     #     # Convert to uint8 for saving as an image\n#     #     final_saliency_map = (final_saliency_map * 255).astype(np.uint8)\n\n    #     # Save the resulting saliency map with mask applied\n    # #     Image.fromarray(final_saliency_map).save('final_saliency2.png')\n    #     top_coords, top_values = getTopMaxima(final_saliency_map, top_n=6)\n\n    #     print(\"Top 6 Maxima Coordinates:\", top_coords)\n    #     print(\"Top 6 Maxima Values:\", top_values)\n\n    #     image_with_maxima = drawMaximaOnImage(image_rgb, top_coords, radius=5, color='red')\n    #     image_with_maxima = np.array(image_with_maxima)\n    #     # Save the resulting image with highlighted maxima\n    #     Image.fromarray(image_with_maxima).save('highlighted_maxima_{}.png'.format(image_path.split('/')[-1]))","metadata":{"trusted":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. Saliency-based Part Initialization and Feature Extraction\ndef compute_saliency_map(image):\n    # Compute the phase Fourier transform (PFT) for saliency detection\n    img_dft = np.fft.fft2(image)\n    magnitude, phase = np.abs(img_dft), np.angle(img_dft)\n    saliency_map = np.fft.ifft2(np.exp(1j * phase)).real\n    return cv2.GaussianBlur(np.abs(saliency_map), (5, 5), 0)\n\n# def extract_salient_points(image, num_points=6):\n#     saliency_map = compute_saliency_map(image)\n#     keypoints = cv2.goodFeaturesToTrack(saliency_map, num_points, 0.01, 10)\n#     return np.int0(keypoints).reshape(-1, 2)\n\n# def extract_salient_points(image, num_points=6):\n    # saliency_map = compute_saliency_map(image)\n    \n    # # Normalize the saliency map to the range [0, 255] and convert to uint8\n    # saliency_map = cv2.normalize(saliency_map, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n    \n    # # Detect keypoints based on saliency\n    # keypoints = cv2.goodFeaturesToTrack(saliency_map, num_points, 0.01, 10)\n    # return np.int0(keypoints).reshape(-1, 2)\n\n# def extract_salient_points(image, num_points=6):\n#     saliency_map = compute_saliency_map(image)\n    \n#     # Normalize the saliency map to the range [0, 255] and convert to uint8\n#     saliency_map = cv2.normalize(saliency_map, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n    \n#     # Detect keypoints based on saliency\n#     keypoints = cv2.goodFeaturesToTrack(saliency_map, num_points, 0.01, 10)\n#     return np.intp(keypoints).reshape(-1, 2)  # Use np.intp instead of np.int0\n\n# def extract_salient_points(image, num_points=6):\n#     saliency_map = compute_saliency_map(image)\n    \n#     # Normalize the saliency map to the range [0, 255] and convert to uint8\n#     saliency_map = cv2.normalize(saliency_map, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n    \n#     # Detect keypoints based on saliency\n#     keypoints = cv2.goodFeaturesToTrack(saliency_map, num_points, 0.01, 10)\n    \n#     # Check if keypoints were found; if not, return an empty array\n#     if keypoints is None:\n#         print(\"No keypoints detected, returning an empty array.\")\n#         return np.array([])  # Return an empty array if no keypoints detected\n    \n#     # If keypoints are detected, reshape and return them\n#     return np.intp(keypoints).reshape(-1, 2)  # Use np.intp instead of np.int0\n\ndef extract_salient_points(image, mask=None, num_points=6):\n    # First attempt to detect keypoints using cv2.goodFeaturesToTrack\n    saliency_map = compute_saliency_map(image)\n    saliency_map = cv2.normalize(saliency_map, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n    keypoints = cv2.goodFeaturesToTrack(saliency_map, num_points, 0.005, 5)\n    \n    if keypoints is None or len(keypoints) < num_points:\n        # If no keypoints are detected or fewer than required, use fallback\n        print(\"Using fallback method to get top maxima.\")\n        final_saliency_map = getSaliencyMap(image, mask)\n        fallback_keypoints, _ = getTopMaxima(final_saliency_map, top_n=num_points)\n        keypoints = np.array(fallback_keypoints)  # Convert to NumPy array\n    \n    return np.intp(keypoints).reshape(-1, 2)\n\n\n\n# def extract_features(image, keypoints):\n#     # Extract SIFT and color histogram features at keypoint locations\n#     sift = cv2.SIFT_create()\n#     keypoints = [cv2.KeyPoint(x, y, 48) for (x, y) in keypoints]\n#     _, descriptors = sift.compute(image, keypoints)\n#     hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n#     color_hist = cv2.calcHist([hsv], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n#     return descriptors, color_hist.flatten()\n\n# def extract_features(image, keypoints):\n#     # Extract SIFT and color histogram features at keypoint locations\n#     sift = cv2.SIFT_create()\n    \n#     # Ensure keypoints are in float format\n#     keypoints = [cv2.KeyPoint(float(x), float(y), 48) for (x, y) in keypoints]\n#     _, descriptors = sift.compute(image, keypoints)\n    \n#     # Convert image to HSV and calculate color histogram\n#     hsv = cv2.cvtColor(cv2.cvtColor(image, cv2.COLOR_GRAY2BGR), cv2.COLOR_BGR2HSV)\n#     color_hist = cv2.calcHist([hsv], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n#     return descriptors, color_hist.flatten()\n\ndef extract_features(image, keypoints):\n    # If no keypoints were detected, return empty descriptors and color histogram\n    if keypoints.size == 0:\n        return np.array([]), np.zeros(512)  # Return an empty descriptor array and empty histogram\n    \n    # Extract SIFT and color histogram features at keypoint locations\n    sift = cv2.SIFT_create()\n    keypoints = [cv2.KeyPoint(float(x), float(y), 48) for (x, y) in keypoints]\n    _, descriptors = sift.compute(image, keypoints)\n    \n    # Convert image to HSV and calculate color histogram\n    hsv = cv2.cvtColor(cv2.cvtColor(image, cv2.COLOR_GRAY2BGR), cv2.COLOR_BGR2HSV)\n    color_hist = cv2.calcHist([hsv], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]).flatten()\n    \n    return descriptors, color_hist\n\n\n# Extract features for all images\nall_descriptors, all_histograms, all_keypoints = [], [], []\nfor image in images:\n    keypoints = extract_salient_points(image)\n    descriptors, color_hist = extract_features(image, keypoints)\n    all_keypoints.append(keypoints)\n    all_descriptors.append(descriptors)\n    all_histograms.append(color_hist)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T11:35:16.979592Z","iopub.execute_input":"2024-11-06T11:35:16.980085Z","iopub.status.idle":"2024-11-06T11:40:40.011760Z","shell.execute_reply.started":"2024-11-06T11:35:16.980045Z","shell.execute_reply":"2024-11-06T11:40:40.009732Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. Non-Rigid Part Model - EM-like Optimization\ndef initialize_non_rigid_model(descriptors, num_parts=6):\n    # PCA for dimensionality reduction\n    pca = PCA(n_components=128)\n    reduced_descriptors = pca.fit_transform(np.vstack(descriptors))\n    return reduced_descriptors, pca\n\nreduced_descriptors, pca_model = initialize_non_rigid_model(all_descriptors)\n","metadata":{"trusted":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4. Hierarchical Partial Classification - SVM with Hierarchy\ndef train_hierarchical_svm(features, labels, penalty_param=1.0):\n    # Train a hierarchical SVM model with class grouping\n    classifier = SVC(kernel='rbf', class_weight='balanced', C=penalty_param, probability=True)\n    classifier.fit(features, labels)\n    return classifier\n\n# Prepare training data (combine SIFT descriptors and color histograms)\ntrain_features = [np.concatenate((desc.mean(axis=0), hist)) for desc, hist in zip(all_descriptors, all_histograms)]\ntrain_labels = labels\nX_train, X_test, y_train, y_test = train_test_split(train_features, train_labels, test_size=0.2, random_state=42)\n\n# Train the model\nsvm_model = train_hierarchical_svm(X_train, y_train)","metadata":{"trusted":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 5. Testing and Evaluation\ndef evaluate_model(model, X_test, y_test):\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred, average='weighted')\n    recall = recall_score(y_test, y_pred, average='weighted')\n    return accuracy, precision, recall","metadata":{"trusted":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate\naccuracy, precision, recall = evaluate_model(svm_model, X_test, y_test)\nprint(f'Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}')\n\n# End-to-end testing is now set up for the Fish4Knowledge dataset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T11:20:01.863907Z","iopub.execute_input":"2024-11-06T11:20:01.864366Z","iopub.status.idle":"2024-11-06T11:20:14.504219Z","shell.execute_reply.started":"2024-11-06T11:20:01.864327Z","shell.execute_reply":"2024-11-06T11:20:14.502605Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null}]}